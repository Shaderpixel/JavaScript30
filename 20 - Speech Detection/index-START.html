<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Speech Detection</title>
</head>
<body>

  <div class="words" contenteditable>
  </div>

<script>
  window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

  const recognition = new SpeechRecognition();
  //output results as people are speaking
  recognition.interimResults = true;

  let p = document.createElement('p');
  const words = document.querySelector('.words');
  words.appendChild(p);

  recognition.addEventListener('result', e => {
    //returns a SpeechRecognitionResultList not an array or node list

    const transcript = Array.from(e.results)
      .map(result => result[0])
      .map(result => result.transcript)
      .join('');

    p.textContent = transcript;

    if (e.results[0].isFinal) {
      p = document.createElement('p');
      words.appendChild(p);
    }

    console.log(transcript);

    if(transcript.includes('unicorn')) console.log('ðŸ¦„ðŸ¦„ðŸ¦„ðŸ¦„ðŸ¦„ðŸ¦„ðŸ¦„ðŸ¦„ðŸ¦„');
  });

  recognition.addEventListener('end', recognition.start);

  recognition.start();

</script>


  <style>
    html {
      font-size: 10px;
    }

    body {
      background:#ffc600;
      font-family: 'helvetica neue';
      font-weight: 200;
      font-size: 20px;
    }

    .words {
      max-width:500px;
      margin:50px auto;
      background:white;
      border-radius:5px;
      box-shadow:10px 10px 0 rgba(0,0,0,0.1);
      padding:1rem 2rem 1rem 5rem;
      background: -webkit-gradient(linear, 0 0, 0 100%, from(#d9eaf3), color-stop(4%, #fff)) 0 4px;
      background-size: 100% 3rem;
      position: relative;
      line-height:3rem;
    }
    p {
      margin: 0 0 3rem;
    }

    .words:before {
      content: '';
      position: absolute;
      width: 4px;
      top: 0;
      left: 30px;
      bottom: 0;
      border: 1px solid;
      border-color: transparent #efe4e4;
    }
  </style>

</body>
</html>

<!--
Lesson Learnt
1. SpeechRecognitionResultList> SpeechRecognitionResult > SpeechRecofnitionAlternative
contains information about the percentage confidence on accuracy, the transcript of what's said, and isFinal bool whether the person has stopped speaking
2.When the recognition.start begins picking up audio, it will produce results which triggers the event result. When there is no longer audio, the result event ends and the event will unbind itself. To keep listening, we need a second event where it detects on end of voice, run the recognition.start again.

Personal Challenge: write a function to hook it up to a weather api to grab weather info
 -->
